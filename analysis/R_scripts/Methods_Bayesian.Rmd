---
title: "Overshoot Bayesian Methods"
author: "Kevin See"
output:
  bookdown::word_document2:
    fig_height: 6
    fig_width: 6
    always_allow_html: true
  bookdown::pdf_document2:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
  bookdown::html_document2:
    fig_height: 6
    fig_width: 6
fontsize: 12pt
mainfont: Times New Roman
---

```{r setup, echo = F}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  echo = FALSE,
  message = FALSE,
  comment = "#>"
)
```

```{r load-packages}
# load needed libraries
library(tidyverse)
library(readxl)
library(magrittr)
library(msm)
library(ggrepel)
library(ggpubr)
library(scales)
library(here)
library(STADEM)

library(knitr)
library(kableExtra)

# theme_set(theme_bw())
theme_set(theme_pubr())

# default options for tables
options(knitr.kable.NA = '-')

# when knitting to Word, use this
# what kind of document is being created?
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')

if(doc.type == 'docx') {
  options(knitr.table.format = "pandoc")
}

```

```{r tot-adj-prd-cnts, eval = F}
library(STADEM)

prd_adj_cnts <- tibble(year = 2011:2018) %>%
  mutate(prd_adj = map(year,
                       .f = function(yr) {
                         
                         
                         # load compressed detections and biological data
                         load(paste0("C:/Users/seek1477/OneDrive - Washington State Executive Branch Agencies/Documents/Git/MyProjects/DabomPriestRapidsSthd/analysis/data/derived_data/PITcleanr/UC_Steelhead_", yr, '.rda'))
                         
                         org_df <- bio_df %>%
                           mutate(origin = recode(origin,
                                                  "H" = "Hatchery",
                                                  "W" = "Wild")) %>%
                           group_by(origin) %>%
                           summarise(n_tags = n_distinct(tag_code)) %>%
                           mutate(prop = n_tags / sum(n_tags),
                                  prop_se = sqrt((prop * (1 - prop)) / sum(n_tags)))
                         
                         # load JAGS MCMC results
                         # load(paste0("C:/Users/seek1477/OneDrive - Washington State Executive Branch Agencies/Documents/Git/MyProjects/DabomPriestRapidsSthd/analysis/data/derived_data/model_fits/PRA_DABOM_Steelhead_", yr,'.rda'))
                         # 
                         # load("C:/Users/seek1477/OneDrive - Washington State Executive Branch Agencies/Documents/Git/MyProjects/DabomPriestRapidsSthd/analysis/data/derived_data/site_config.rda")
                         # # compile all movement probabilities, and multiply them appropriately
                         # trans_df = compileTransProbs_PRA(dabom_mod,
                         #                                  parent_child) %>%
                         #   mutate(origin = recode(origin,
                         #                          "2" = "Hatchery",
                         #                          "1" = "Wild"))
                         # 
                         # trans_df %>%
                         #   filter(param %in% c('ICH', 'JD1', 'JDA', 'PRH', 'PRO', 'PRV', 'RSH', 'TMF')) %>%
                         #   group_by(chain, iter, origin) %>%
                         #   summarize(across(value,
                         #                    sum),
                         #             .groups = "drop") %>%
                         #   group_by(origin) %>%
                         #   summarize(across(value,
                         #                    list(mean = mean,
                         #                         median = median,
                         #                         sd = sd)))

                         # org_df <- enframe(jags_data$fish_type,
                         #                   name = "fish_num",
                         #                   value = "origin") %>%
                         #   mutate(origin = recode(origin,
                         #                          "1" = "Wild",
                         #                          "2" = "Hatchery")) %>%
                         #   group_by(origin) %>%
                         #   summarise(n_tags = n_distinct(fish_num)) %>%
                         #   mutate(prop = n_tags / sum(n_tags),
                         #          prop_se = sqrt((prop * (1 - prop)) / sum(n_tags)))
                         
                         
                         start_date = paste0(yr-1, '0601')
                         end_date = paste0(yr, '0531')
                         
                         
                         # start with PIT-tag based reascension data
                         org_escape = queryPITtagData(damPIT = 'PRA',
                                                      spp = "Steelhead",
                                                      start_date = start_date,
                                                      end_date = end_date) %>%
                           filter(!str_detect(TagId, "000.0")) %>%
                           mutate(SpawnYear = yr) %>%
                           mutate(across(TagIdAscentCount,
                                         tidyr::replace_na,
                                         0)) %>%
                           mutate(ReAscent = ifelse(TagIdAscentCount > 1, T, F)) %>%
                           group_by(Species, SpawnYear, Date) %>%
                           summarise(tot_tags = n_distinct(TagId),
                                     reascent_tags = n_distinct(TagId[ReAscent]),
                                     .groups = "drop") %>%
                           group_by(Species, SpawnYear) %>%
                           summarise(across(matches('tags'),
                                            sum,
                                            na.rm = T),
                                     .groups = "drop") %>%
                           mutate(reasc_rate = reascent_tags / tot_tags,
                                  reasc_rate_se = sqrt(reasc_rate * (1 - reasc_rate) / tot_tags)) %>%
                           # add window counts
                           bind_cols(getWindowCounts(dam = 'PRD',
                                                     spp = "Steelhead",
                                                     start_date = start_date,
                                                     end_date = end_date) %>%
                                       summarise_at(vars(win_cnt),
                                                    list(sum),
                                                    na.rm = T) %>%
                                       select(tot_win_cnt = win_cnt)) %>%
                           mutate(adj_win_cnt = tot_win_cnt * (1 - reasc_rate),
                                  adj_win_cnt_se = tot_win_cnt * reasc_rate_se) %>%
                           bind_cols(org_df) %>%
                           rowwise() %>%
                           mutate(tot_escp = adj_win_cnt * prop,
                                  tot_escp_se = msm::deltamethod(~ x1 * x2,
                                                                 mean = c(adj_win_cnt, prop),
                                                                 cov = diag(c(adj_win_cnt_se, prop_se)^2))) %>%
                           select(Species, SpawnYear, origin, 
                                  matches("cnt"),
                                  matches("reasc_rate"), 
                                  matches('escp'))
                         
                         return(org_escape)
                       })) %>%
  unnest(prd_adj) %>%
  select(-Species,
         -SpawnYear)

prd_adj_cnts %>% 
  select(year, origin, tot_escp) %>% 
  pivot_wider(names_from = origin, 
              values_from = tot_escp) %>% 
  select(year, Wild, Hatchery)

# tibble(year = 2011:2018) %>%
#   mutate(escp = map(year,
#                     function(yr) {
#                       # read_excel(here(paste0('analysis/data/derived_data/',
#                       #                        'DABOM_results/PRA_Steelhead_', x[1], '_20190610.xlsx')),
#                       read_excel(here(paste0('analysis/data/derived_data/',
#                                              'DABOM_results/UC_Steelhead_', yr, '_20211122.xlsx')),
#                                  1) %>%
#                         rename(location = group) %>%
#                         mutate(origin = recode(origin,
#                                                "W" = "Wild",
#                                                "H" = "Hatchery")) %>%
#                         bind_rows(read_excel(here(paste0('analysis/data/derived_data/',
#                                                          'DABOM_results/UC_Steelhead_', yr, '_20211122.xlsx')),
#                                              2) %>%
#                                     filter(location %in% c("PRA_bb",
#                                                            "RIA_bb",
#                                                            "RRF_bb")) %>%
#                                     mutate(origin = recode(origin,
#                                                            "1" = "Wild",
#                                                            "2" = "Hatchery"))) %>%
#                         # group_by(origin) %>%
#                         summarize(across(estimate,
#                                          sum))
#                     }))

```


```{r read-data}
# read in data
obs_ovrsht_org = read_excel(here('analysis/data/raw_data/overshoot estimates.xlsx'),
                            range = 'A3:C10',
                            col_names = c('Year',
                                          'juv_tags',
                                          'pom_overshoots')) %>%
  mutate(origin = 'Wild',
         location = 'downstream_PRA') %>%
  bind_rows(read_excel(here('analysis/data/raw_data/overshoot estimates.xlsx'),
                       range = 'A19:B26',
                       col_names = c('Year',
                                     'juv_tags')) %>%
              mutate(origin = 'Wild',
                     location = 'at_PRA')) %>%
  bind_rows(read_excel(here('analysis/data/raw_data/overshoot estimates.xlsx'),
                       range = 'A31:C38',
                       col_names = c('Year',
                                     'juv_tags',
                                     'pom_overshoots')) %>%
              mutate(origin = 'Hatchery',
                     location = 'downstream_PRA')) %>%
  bind_rows(read_excel(here('analysis/data/raw_data/overshoot estimates.xlsx'),
                       range = 'A47:B54',
                       col_names = c('Year',
                                     'juv_tags')) %>%
              mutate(origin = 'Hatchery',
                     location = 'at_PRA')) %>%
  select(Year,
         Origin = origin,
         location,
         everything()) %>%
  arrange(location, Origin, Year)

# data on individual overshoots
obs_ovrsht = read_excel(here("analysis/data/raw_data/known overshoot fallback locations.xlsx")) %>%
  janitor::clean_names() %>%
  rename(notes = x5,
         site = downstream_obs_site) %>%
  tidyr::fill(total) %>%
  mutate(year = year + 1)

# estimated overshoots
est_ovrsht = obs_ovrsht %>%
  group_by(Year = year, site) %>%
  summarise(obs_ovrst_tags = n_distinct(pit_tag)) %>%
  ungroup() %>%
  # get estimates of downstream detection prob
  left_join(as.list(2011:2018) %>%
              rlang::set_names() %>%
              map_df(.id = 'Year',
                     .f = function(x) {
                       # read_excel(here(paste0('analysis/data/derived_data/',
                       #                        'DABOM_results/PRA_Steelhead_', x[1], '_20190610.xlsx')),
                       read_excel(here(paste0('analysis/data/derived_data/',
                                              'DABOM_results/UC_Steelhead_', x[1], '_20211122.xlsx')),
                                  "Detection") %>%
                         janitor::clean_names()
                     }) %>%
              mutate_at(vars(Year),
                        list(as.numeric)) %>%
              filter(!grepl("A0$", node)) %>%
              mutate(site = str_remove(node, "B0$")) %>%
              select(Year, site, 
                     det_est = estimate, 
                     det_se = se)) %>%
  # drop sites with no detection probability: they are all not the head of branches
  filter(!is.na(det_est)) %>%
  mutate(beta_alpha = ((1 - det_est) / det_se^2 - 1 / det_est) * det_est^2,
         beta_alpha = if_else(beta_alpha < 0, 0.01, beta_alpha),
         beta_beta = beta_alpha * (1 / det_est - 1)) %>%
  mutate(beta_alpha = if_else(det_est == 1, 1, beta_alpha),
         beta_beta = if_else(det_est == 1, 0, beta_beta)) %>%
  mutate(est_ovrst_tags = obs_ovrst_tags / det_est,
         # est_ovrst_tags = floor(est_ovrst_tags),
         est_ovrst_tags = round(est_ovrst_tags),
         rho = 1 / (beta_alpha + beta_beta + 1),
         var_ovrst_tags = est_ovrst_tags * det_est * (1 - det_est) * (1 + (est_ovrst_tags - 1)*rho),
         se_ovrst_tags = sqrt(var_ovrst_tags)) %>%
  mutate(Origin = 'Wild') %>%
  select(Year, Origin, everything())

# get estimates of downstream escapement
dwnstrm_est = as.list(2011:2018) %>%
  rlang::set_names() %>%
  map_df(.id = 'Year',
         .f = function(x) {
           # read_excel(here(paste0('analysis/data/derived_data/',
           #                        'DABOM_results/PRA_Steelhead_', x[1], '_20190610.xlsx')),
           #            1) %>%
           #   filter(Population == 'BelowPriest')
           
           read_excel(here(paste0('analysis/data/derived_data/',
                                  'DABOM_results/UC_Steelhead_', x[1], '_20211122.xlsx')),
                      1) %>%
             filter(group == 'BelowPriest') %>%
             rename(Population = group,
                    Origin = origin,
                    Estimate = estimate,
                    SE = se)
           
         }) %>%
  mutate_at(vars(Year),
            list(as.numeric)) %>%
  mutate(Origin = recode(Origin,
                         'W' = 'Wild',
                         "H" = "Hatchery"))

# join escapement estimates and estimated overshoot tags, using all branches and all overshoot tags
# Andrew's preferred method
mod_data = est_ovrsht %>%
  group_by(Year, Origin) %>%
  summarise(tags_obs = sum(obs_ovrst_tags),
            det_prob = mean(det_est),
            det_prob_wgt = weighted.mean(det_est, w = est_ovrst_tags),
            tags_est = sum(est_ovrst_tags),
            tags_se = sqrt(sum(se_ovrst_tags^2))) %>%
  ungroup() %>%
  full_join(dwnstrm_est %>%
              filter(Origin == "Wild") %>%
              select(-Population) %>%
              rename(escp_est = Estimate,
                     escp_se = SE,
                     escp_lwr = lowerCI,
                     escp_upr = upperCI))

#-------------------------------------------------
# turn it into data for JAGS
jags_data = mod_data %>%
  select(Year, Origin, tags_est:escp_se) %>%
  mutate(tags_prec = 1 / tags_se^2,
         escp_prec = 1 / escp_se^2,
         escp_est_log = log(escp_est)) %>%
  select(-ends_with("se"),
         -Origin) %>%
  select(-escp_est,
         -escp_prec,
         -Year) %>%
  select(-species,
         -spawn_year) %>%
  as.list()

# add data for predictions
# known overshoot tags observed at PRA, their origin, and POM estimates of downstream escapement
jags_data = c(jags_data,
              obs_ovrsht_org %>%
                filter(location == "at_PRA") %>%
                select(Year, Origin, ovrst_tags = juv_tags) %>%
                left_join(dwnstrm_est %>%
                            select(Year, Origin, dwnstrm_escp = Estimate, dwnstrm_se = SE)) %>%
                # filter(Origin == 'Wild') %>%
                # mutate(ovrst_org = as.numeric(as.factor(Origin))) %>%
                select(-Year,
                       -Origin) %>%
                as.list())


```

```{r avg-detection, eval = T}
# average detection at sites
avg_det = as.list(2011:2018) %>%
  rlang::set_names() %>%
  map_df(.id = 'Year',
         .f = function(x) {
           # read_excel(here(paste0('analysis/data/derived_data/',
           #                        'DABOM_results/PRA_Steelhead_', x[1], '_20190610.xlsx')),
           read_excel(here(paste0('analysis/data/derived_data/',
                                              'DABOM_results/UC_Steelhead_', x[1], '_20211122.xlsx')),
                      "Detection") %>%
             janitor::clean_names()
         }) %>%
  mutate_at(vars(Year),
            list(as.numeric)) %>%
  filter(grepl('PRO', node) |
           grepl('ICH', node) |
           grepl('PRV', node) |
           grepl('TMF', node) |
           grepl('^JD1', node)) %>%
  filter(!grepl('A0$', node)) %>%
  mutate(node = str_remove(node, "B0$")) %>%
  mutate(cv = se / estimate) %>%
  group_by(node) %>%
  summarise(mean_tags = mean(n_tags),
            mean = mean(estimate),
            sd_est = sd(estimate),
            mean_se = mean(se),
            mean_cv = mean(cv, na.rm = T))

```

```{r dwnstrm_abund}
# get branch specific estimates of downstream escapement
# dwnstrm_loc_est = as.list(2011:2018) %>%
#   rlang::set_names() %>%
#   map_df(.id = 'Year',
#          .f = function(x) {
#            read_excel(here(paste0('analysis/data/derived_data/',
#                                   'DABOM_results/PRA_Steelhead_', x[1], '_20190610.xlsx')),
#              filter(param %in% c("BelowJD1",
#                                  'past_RSH',
#                                  'past_PRH',
#                                  'past_JD1',
#                                  'past_TMF',
#                                  'past_ICH',
#                                  'past_PRO',
#                                  'past_PRV')) %>%
#              rename(site = param) %>%
#              mutate(site = str_remove(site, "^past_"))
#          }) %>%
#   mutate_at(vars(Year),
#             list(as.numeric)) %>%
#   mutate(Origin = recode(Origin,
#                          'Natural' = 'Wild')) %>%
#   rename(pom_est = Estimate,
#          pom_se = SE,
#          pom_ci_low = lowerCI,
#          pom_ci_high = upperCI)

dwnstrm_loc_est = as.list(2011:2018) %>%
  rlang::set_names() %>%
  map_df(.id = 'Year',
         .f = function(x) {
           read_excel(here(paste0('analysis/data/derived_data/',
                                  'DABOM_results/UC_Steelhead_', x[1], '_20211122.xlsx')),
                      2) %>%
             filter(location %in% c("JDA",
                                    'RSH',
                                    'PRH',
                                    'JD1',
                                    'TMF',
                                    'ICH',
                                    'PRO',
                                    'PRV')) %>%
             rename(site = location)
         }) %>%
  mutate_at(vars(Year),
            list(as.numeric)) %>%
  rename(Origin = origin) %>%
  mutate(Origin = recode(Origin,
                         '1' = 'Wild',
                         '2' = 'Hatchery')) %>%
  rename(pom_est = estimate,
         pom_se = se,
         pom_ci_low = lowerCI,
         pom_ci_high = upperCI)

           

# re-shape data
flbk_abund = dwnstrm_loc_est %>%
  select(Year:pom_est) %>%
  mutate(Origin = recode(Origin,
                         "Hatchery" = 'H', 
                         "Wild" = "W")) %>%
  pivot_wider(names_from = c("site", "Origin"),
              values_from = "pom_est") %>%
  select(Year,
         ends_with("W"),
         ends_with("H")) %>%
  select(Year, 
         starts_with('PRO'),
         starts_with('ICH'),
         starts_with('PRV'),
         starts_with('TMF'),
         starts_with('JD1'))

```


# Goal

Estimate the number of overshoots that reach Priest. If PIT tag rates for wild steelhead were known, we could expand detection (assuming 100%) at PRD of known overshoots (juveniles PIT tagged from MCR and SR DPS and detected at PRD) to estimate overshoot abundance at PRD. Since population specific PIT tag rates are unknown we need another method to estimate overshoot abundance.

# Available Data

* Number of fish tagged as juveniles from downstream areas that are detected at Priest in year $i$ ($T_i$).
* Number of fish tagged as juveniles from downstream areas that are detected at Priest and detected succesfully falling back and entering downstream area $j$ which is part of the patch-occupancy model in year $i$ ($s_{i,j}$).
* Estimates, from patch-occupancy model, of total fallbacks (fish that crossed Priest, then fell back and entered a downstream tributary) in year $i$ ($F_i$). These are based on a different set of tags from adults tagged at Priest, who are detected downstream. It accounts for imperfect detection at the downstream arrays.
* Estimates, from patch-occupancy model, of detection probability of all downstream sites.

The detection probability estimates are shown in Table \@ref(tab:det-prob-tab). Estimates of fallback abundance from the POM are shown in Table \@ref(tab:flbk-est).

```{r det-prob-tab}
avg_det %>%
  arrange(desc(mean_tags)) %>%
  select(Site = node,
         `Avg Tags` = mean_tags,
         Mean = mean,
         `SD of Mean` = sd_est,
         `Avg SE` = mean_se,
         `Avg CV` = mean_cv) %>%
  kable(booktabs = T,
        linesep = "",
        digits = c(0, 0, rep(3, 4)),
        caption = "Summaries of detection probabilities of sites downstream of PRD.") %>%
  kable_styling()
```

Re-create Table 2
```{r flbk-est}
flbk_abund %>%
  mutate_at(vars(Year),
            list(as.character)) %>%
  bind_rows(flbk_abund %>%
              summarise_at(vars(-Year),
                           list(mean)) %>%
              mutate(Year = "Mean")) %>%
  kable(digits = 0,
        booktabs = T,
        linesep = "",
        caption = "Estimates by subbasin and PTAGIS code of overshoot fallback steelhead downstream of Priest Rapids Dam. (PRO = Prosser Dam; ICH = Ice Harbor Dam; PRV = Pierce RV Park instream array; TMF = Three Mile Falls Dam; JD1 = Lower John Day at McDonald Ferry).") %>%
  kable_styling(latex_options = c("scale_down"))
```

```{r flbk-est-save, eval = F}
# save as csv
flbk_abund %>%
  mutate_at(vars(Year),
            list(as.character)) %>%
  bind_rows(flbk_abund %>%
              summarise_at(vars(-Year),
                           list(mean)) %>%
              mutate(Year = "Mean")) %>%
  write_csv(here('analysis/outgoing/Table2.csv'))
```


# Methods

First, we need to account for imperfect detection at the downstream sites so we can expand the number of known overshoot tags detected there. We do that by using the estimates of detection probablity from the patch-occupancy model for year $i$ at each site $j$, and then summing up the estimated tags at each detection site to get an estimate of total overshoot return tags, $\hat{t_i}$. 

$$
t_i = \sum_j^J \frac{s_{i,j}}{\hat{p_{i,j}}}
$$

Next, we develop a relationship between the number of overshoot return tags, $t_i$ and the total overshoot return abundance, $F_i$. We assumed a log-log relationship (see Figure @\ref(fig:tag_escp_fig)).

$$
F_i \sim e^{\beta_0} * t_i^{\beta_1}\\
\log(F_i) \sim \beta_0 + \beta_1 * \log(t_i)
$$

```{r tag_escp_fig, fig.caption = "Plot of previously tagged fish detected at Priest Rapids and then subsequently detected downstream (adjusted for downstream detection probability) vs estimates of downstream overshoot abundance from the patch-occupancy model."}
mod_data %>%
  ggplot(aes(x = tags_est,
             y = escp_est)) +
  geom_errorbar(aes(ymin = escp_lwr,
                    ymax = escp_upr),
                width = 0) +
  geom_errorbarh(aes(xmin = tags_est + tags_se * qnorm(0.025),
                     xmax = tags_est + tags_se * qnorm(0.975)),
                 height = 0) +
  geom_point() +
  geom_smooth(method = glm,
              formula = y ~ log(x),
              method.args = list(family = gaussian(link = 'log')),
              se = F,
              fullrange = T,
              aes(color = "Log-log")) +
  geom_smooth(method = glm,
              formula = y ~ x,
              method.args = list(family = gaussian(link = 'identity')),
              se = F,
              fullrange = T,
              aes(color = "Linear")) +
  scale_color_brewer(palette = "Set1",
                     name = "Model") +
  labs(x = 'Wild Adults Tagged as Juveniles\nthat Returned Downstream',
       y = 'Total Successful Overshoots (from POM)')

# ggsave(here('analysis/figures/log_log_regression.pdf'),
#        width = 6,
#        height = 6)

```

We then use that relationship, ($\hat{\beta}$), and the total number of known overshoot tags observed at Priest, $T_i$, to predict the total overshoot abundance at Priest, $O_i$. The overshoot return survival, $\phi_i$, is the calculated from that and the estimate of total downstream abundance.

$$
\phi_i = \frac{R_i}{O_i}
$$

Written out mathematically, the whole things looks like this:


$$
\begin{aligned}
\mu_i &= \sum_j^J \frac{s_{i,j}}{\hat{p_{i,j}}} \\
t_i &\sim N(\mu_i, \sigma^2_i) \\
\\
F_i &\sim e^{\beta_0} * t_i^{\beta_1} \\
\log(F_i) &= \beta_0 + \beta_1 * \log(t_i) + e_i\\
e_i &\sim N(0, \tau^2) \\
\\
\log(O_i) &\sim N(\hat{\beta_0} + \hat{\beta_1} * \log(T_i), \hat{\tau^2}) \\
\\
R_i &\sim N(F_i, \gamma^2) \\
\\
\phi_i &= \frac{R_i}{O_i} \approx \left( \frac{t_i}{T_i} \right)^{\beta_1} \\
\end{aligned}
$$

We fit this entire model in a Bayesian framework, using JAGS software. The JAGS model looks like this:

```{r jags_model, echo = T}
jags_model = function() {
  "  # PRIORS
  for(i in 1:2) {
    beta[i] ~ dt(0, 0.01, 1)
  }
  sigma ~ dt(0, 0.01, 1)T(0,)
  tau <- pow(sigma, -2)
  
  # MODEL
  for(i in 1:length(tags_est)) {
    n_tags_org[i] ~ dnorm(tags_est[i], tags_prec[i])
    n_tags[i] <- round(n_tags_org[i])
    
    # couldn't figure out how to incorporate this uncertainty, 
    # because n_escp_log would end up on the left side twice
    # n_escp_log[i] ~ dlnorm(escp_est[i], escp_prec[i])
    
    mu[i] <- beta[1] + beta[2] * log(n_tags[i])
    
    # assuming downstream escapement estimates are known
    escp_est_log[i] ~ dnorm(mu[i], tau)
  }
  
  for(i in 1:length(ovrst_tags)) {
    # deal with uncertainty in downstream escapement estimates
    est_dwnstrm_org[i] ~ dnorm(dwnstrm_escp[i], 1 / (dwnstrm_se[i]^2))
    est_dwnstrm[i] <- round(est_dwnstrm_org[i])
    
    # predict the number of overshoot fish at Priest
    pred_mu_log[i] <- beta[1] + beta[2] * log(ovrst_tags[i])
    pred_ovrshts_log[i] ~ dnorm(pred_mu_log[i], tau)T(log(est_dwnstrm[i]), log(1e4))
    pred_ovrshts[i] <- round(exp(pred_ovrshts_log[i]))

    # estimate survival of overshoots
    phi[i] <- est_dwnstrm[i] / pred_ovrshts[i]
  }"
}
```

```{r run-model, eval = F}
library(postpack)
library(rjags)

# write model to a text file
jags_file = here("analysis/R_scripts",
                 "model.txt")
write_model(jags_model, jags_file)

# which paramters to track?
jags_params = c("beta",
                "sigma",
                "mu",
                "n_tags",
                "phi",
                "est_dwnstrm",
                "pred_ovrshts")

# using rjags package
set.seed(3)
jags = jags.model(jags_file,
                  data = jags_data,
                  inits = list(pred_ovrshts_log = log(jags_data$dwnstrm_escp + 10)),
                  n.chains = 4,
                  n.adapt = 2000)

# burnin
update(jags, n.iter = 50000)
# posterior sampling
post = coda.samples(jags,
                    jags_params,
                    n.iter = 50000,
                    thin = 25)

# convert posteriors into long tibble
post_df = as.matrix(post,
                    chains = T,
                    iters = T) %>%
  as_tibble() %>%
  pivot_longer(cols = c(-CHAIN, -ITER),
               names_to = 'param',
               values_to = 'value') %>%
  mutate(param_fam = str_split(param, "\\[", simplify = T)[,1],
         param_num = str_extract(param, "[:digit:]+"),
         param_num = as.numeric(param_num))

param_summ = post_summ(post,
                       jags_params,
                       Rhat = T,
                       neff = T) %>%
  t() %>%
  as_tibble(rownames = "param") %>%
  mutate(cv = sd / mean)

save(mod_data, jags_data, post, param_summ, post_df,
     file = here("analysis/data/derived_data/mcmc_output.rda"))
```

# Results

```{r load-model}
library(postpack)
library(rjags)

load(here("analysis/data/derived_data/mcmc_output.rda"))
```

```{r model-diagnostics, eval=F}
diag_plots(post, "sigma")

# test for normality of residuals
resid_df <- post_df %>% 
  filter(str_detect(param, "mu")) %>% 
  mutate(obs = rep(jags_data$escp_est_log, 4000)) %>% 
  mutate(resid = obs - value)

ggqqplot(resid_df$resid)
ggdensity(resid_df$resid,
          fill = "lightgrey")

ggplot(resid_df,
       aes(x = resid)) +
  geom_histogram(aes(fill = param),
                 binwidth = 0.05)

ggplot(resid_df) +
  geom_density(aes(x = resid),
               fill = "lightgray") +
  geom_function(fun = dnorm,
                args = list(mean = 0, 
                            sd = 0.568),
                color = "red")

mean_resid_df <- resid_df %>%
  group_by(param) %>%
  summarize(across(c(value, obs, resid),
                   mean),
            .groups = "drop")

ggqqplot(mean_resid_df$resid)
ggdensity(mean_resid_df$resid,
          fill = "lightgrey")
shapiro.test(mean_resid_df$resid)

diag_plots(post, "phi")

```


```{r comp-fig, fig.cap = "Comparison of total adusted counts at Priest and the sum of predicted overshoots and escapement to four upper Columbia steelhead populations."}
#--------------------------------------------------
# compare counts at Priest and estimates across UC pops
#--------------------------------------------------
uc_pops = as.list(2011:2018) %>%
  rlang::set_names() %>%
  map_df(.id = 'Year',
         .f = function(x) {
           read_excel(here(paste0('analysis/data/derived_data/DABOM_results/UC_Steelhead_', x[1], '_20211122.xlsx')),
                      "Population Escapement") %>%
             janitor::clean_names()
         }) %>%
  filter(group %in% c("Wenatchee",
                      "Entiat",
                      "Methow",
                      "Okanogan")) %>%
  select(Year, Group = group,
         origin, estimate, se) %>%
  mutate(across(Year,
                as.integer))

# pra_total = as.list(2011:2018) %>%
#   rlang::set_names() %>%
#   map_df(.id = 'Year',
#          .f = function(x) {
#            read_excel(here(paste0('analysis/data/derived_data/DABOM_results/UC_Steelhead_', x[1], '_20211122.xlsx')),
#                       "All Escapement") %>%
#              janitor::clean_names()
#          }) %>%
#   filter(location %in% c("RIA",
#                          'ICH', 'JD1', 'JDA', 'PRH', 'PRO', 'PRV', 'RSH', 'TMF',
#                          "PRA_bb")) %>%
#   group_by(Year, origin) %>%
#   summarize(estimate = sum(estimate),
#             se = sqrt(sum(se^2)),
#             .groups = "drop") %>%
#   mutate(origin = recode(origin,
#                          "1" = "W",
#                          "2" = "H")) %>%
#   add_column(Group = "PRD Adj. Counts",
#              .after = "Year")

pra_total <- tibble(Year = 2011:2018) %>%
  mutate(pra_cnts = map(Year,
                        .f = function(yr) {
                          start_date = paste0(yr-1, '0601')
                          end_date = paste0(yr, '0531')
                          
                          load(here("analysis/data/derived_data/DABOMready",
                                    paste0("UC_Steelhead_", yr, ".rda")))
                          
                          org_escape = queryPITtagData(damPIT = 'PRA',
                                                       spp = "Steelhead",
                                                       start_date = start_date,
                                                       end_date = end_date) %>%
                            filter(!str_detect(TagId, "000.0")) %>%
                            mutate(SpawnYear = yr) %>%
                            mutate(across(TagIdAscentCount,
                                          tidyr::replace_na,
                                          0)) %>%
                            mutate(ReAscent = ifelse(TagIdAscentCount > 1, T, F)) %>%
                            group_by(Species, SpawnYear, Date) %>%
                            summarise(tot_tags = n_distinct(TagId),
                                      reascent_tags = n_distinct(TagId[ReAscent]),
                                      .groups = "drop") %>%
                            group_by(Species, SpawnYear) %>%
                            summarise(across(matches('tags'),
                                             sum,
                                             na.rm = T),
                                      .groups = "drop") %>%
                            mutate(reasc_rate = reascent_tags / tot_tags,
                                   reasc_rate_se = sqrt(reasc_rate * (1 - reasc_rate) / tot_tags)) %>%
                            # add window counts
                            bind_cols(getWindowCounts(dam = 'PRD',
                                                      spp = "Steelhead",
                                                      start_date = start_date,
                                                      end_date = end_date) %>%
                                        summarise_at(vars(win_cnt),
                                                     list(sum),
                                                     na.rm = T) %>%
                                        select(tot_win_cnt = win_cnt)) %>%
                            mutate(adj_win_cnt = tot_win_cnt * (1 - reasc_rate),
                                   adj_win_cnt_se = tot_win_cnt * reasc_rate_se) %>%
                            bind_cols(bio_df %>%
                                        group_by(origin) %>%
                                        summarise(n_tags = n_distinct(tag_code)) %>%
                                        mutate(prop = n_tags / sum(n_tags),
                                               prop_se = sqrt((prop * (1 - prop)) / sum(n_tags)))) %>%
                            rowwise() %>%
                            mutate(tot_escp = adj_win_cnt * prop,
                                   tot_escp_se = msm::deltamethod(~ x1 * x2,
                                                                  mean = c(adj_win_cnt, prop),
                                                                  cov = diag(c(adj_win_cnt_se, prop_se)^2))) %>%
                            select(Species, SpawnYear, origin, reasc_rate, matches('escp'))
                          
                          return(org_escape)

                        })) %>%
  unnest(pra_cnts) %>%
  mutate(Group = "PRD Adj. Counts") %>%
  select(Year, Group,
         origin,
         estimate = tot_escp,
         se = tot_escp_se)

comp_df <- pra_total %>%
  bind_rows(uc_pops) %>%
  bind_rows(param_summ %>%
              filter(grepl('pred_ovrshts', param)) %>%
              bind_cols(obs_ovrsht_org %>%
                          filter(location == "at_PRA") %>%
                          select(Year, Origin,
                                 juv_tags)) %>%
              select(Year, origin = Origin,
                     estimate = mean,
                     se = sd) %>%
              mutate(origin = recode(origin,
                                     "Hatchery" = "H",
                                     "Wild" = "W")) %>%
              add_column(Group = "Overshoots",
                         .after = "Year")) %>%
  mutate(across(Group,
                factor,
                levels = c("PRD Adj. Counts",
                           "Overshoots",
                           "Wenatchee",
                           "Entiat",
                           "Methow",
                           "Okanogan"))) %>%
  arrange(origin, Year, Group)

comp_summ = comp_df %>%
  filter(Group %in% c("Wenatchee",
                      "Entiat",
                      "Methow",
                      "Okanogan")) %>%
  group_by(Year, origin) %>%
  summarize(estimate = sum(estimate),
            se = sqrt(sum(se^2)),
            .groups = "drop") %>%
  add_column(Group = "uc_pops",
             .after = "Year") %>%
  bind_rows(comp_df %>%
              filter(Group %in% c("PRD Adj. Counts",
                                  "Overshoots"))) %>%
  mutate(across(Group,
                recode,
                'PRD Adj. Counts' = 'PRA')) %>%
  select(-se) %>%
  pivot_wider(names_from = Group,
              values_from = estimate) %>%
  mutate(uc_plus_ovrst = uc_pops + Overshoots,
         leftover = PRA - uc_plus_ovrst,
         abs_diff = abs(leftover),
         rel_diff = leftover / PRA,
         rel_abs_diff = abs(rel_diff)) %>%
  arrange(origin, Year)
  
# 
# comp_summ %>%
#   group_by(origin) %>%
#   summarise_at(vars(PRA, uc_pops,
#                     Overshoots,
#                     uc_plus_ovrst,
#                     leftover, abs_diff,
#                     rel_diff, rel_abs_diff),
#                list(mean)) %>%
#   mutate(abs_rel_diff = abs_diff / PRA)
# 
# comp_summ %>%
#   group_by(origin) %>%
#   summarise(PRA_mean = mean(PRA),
#             RMSE = sqrt(mean(leftover^2)),
#             rel_RMSE = RMSE / PRA_mean)
# 
# comp_summ %>%
#   select(uc_plus_ovrst, PRA) %>%
#   corrr::correlate()



comp_summ %>%
  filter(origin == "W") %>%
  ggplot(aes(x = Year)) +
  geom_line(aes(y = PRA,
                color = "At Priest")) +
  geom_point(aes(y = PRA,
                 color = "At Priest"),
             size = 3) +
  geom_line(aes(y = uc_plus_ovrst,
                color = "UC Pops plus Est. Overshoots")) +
  geom_point(aes(y = uc_plus_ovrst,
                 color = "UC Pops plus Est. Overshoots"),
             size = 3) +
  scale_color_brewer(palette = "Set1",
                     name = "Source") +
  theme(legend.position = "bottom") +
  facet_wrap(~ origin,
             scales = 'fixed') +
  labs(y = "Total Steelhead")
```

Figure 5

```{r fig-prd-cnts, fig.cap = "Comparison between adjusted dam counts at PRD (circles) and summed estimates of the four Upper Columbia steelhead populations plus estimates of steelhead overshoots at PRD. Whiskers represent 95% confidence intervals of those sums, most of which is due to uncertainty of overshoot estimates."}
tot_summ <- comp_df %>%
  filter(origin == "W",
         Group != "PRD Adj. Counts") %>%
  group_by(Year) %>%
  summarize(estimate = sum(estimate),
            se = sqrt(sum(se^2)))

comp_df %>%
  filter(origin == "W",
         Group != "PRD Adj. Counts") %>%
  mutate(across(Group,
                fct_drop)) %>%
  ggplot(aes(x = Year,
             y = estimate)) +
  geom_col(aes(fill = Group),
           color = "black") +
  # geom_col_pattern(aes(pattern = Group,
  #                      fill = Group),
  #                  pattern_fill = "gray80",
  #                  pattern_color = "black") +
  scale_fill_grey(start = 0.9,
                  end = 0.1,
                  name = "Population") +
  geom_errorbar(data = tot_summ,
                aes(ymin = qnorm(0.025, estimate, se),
                    ymax = qnorm(0.975, estimate, se)),
                width = 0.1) +
  geom_point(data = comp_df %>%
               filter(origin == "W",
                      Group == "PRD Adj. Counts"),
             aes(size = Group,
                 shape = Group)) +
  geom_line(data = comp_df %>%
               filter(origin == "W",
                      Group == "PRD Adj. Counts"),
            aes(linetype = Group)) +
  scale_shape_manual(values = c("PRD Adj. Counts" = 1),
                     name = NULL) +
  scale_size_manual(values = c("PRD Adj. Counts" = 4),
                     name = NULL) +
  scale_linetype_manual(values = c("PRD Adj. Counts" = 2),
                     name = NULL) +
  scale_x_continuous(n.breaks = 8) +
  scale_y_continuous(labels = comma) +
  guides(fill = guide_legend(nrow = 5,
                             title.position = "top")) +
  theme_pubr(base_family = "serif",
             base_size = 10) +
  theme(legend.position = c(0.9, 0.8)) +
  labs(y = "Number of Wild Steelhead")

# ggsave(here("analysis/figures",
#             "prd_counts.png"),
#        width = 5,
#        height = 5)

```


# Tables

Recreate Table 1 of manuscript:
```{r tab1}
tab1 <- dwnstrm_est %>%
  pivot_wider(names_from = Origin,
              values_from = Estimate:upperCI) %>%
  select(Year,
         ends_with("Wild"),
         ends_with("Hatchery")) %>%
  left_join(pra_total %>%
              select(-Group, -se) %>%
              pivot_wider(names_from = origin,
                          values_from = estimate) %>%
              rename(adj_tot_Wild = W,
                     adj_tot_Hatchery = H)) %>%
  mutate(perc_Wild = Estimate_Wild / adj_tot_Wild,
         perc_Hatchery = Estimate_Hatchery / adj_tot_Hatchery) %>%
  relocate(perc_Wild,
           .before = Estimate_Wild) %>%
  relocate(perc_Hatchery,
           .before = Estimate_Hatchery) %>%
  select(Year,
         starts_with("adj_tot"),
         ends_with("Wild"),
         ends_with("Hatchery")) %>%
  mutate(Year = as.character(as.numeric(Year) - 1))

tab1_summ <- tab1 %>%
  select(ends_with("Wild"),
         ends_with("Hatchery")) %>%
  summarize(across(everything(),
                   mean)) %>%
  add_column(Year = "Mean",
             .before = 0) %>%
  bind_rows(tab1 %>%
              select(ends_with("Wild"),
                     ends_with("Hatchery")) %>%
              summarize(across(everything(),
                               sd)) %>%
              add_column(Year = "SD",
                         .before = 0))

tab1 %>%
  bind_rows(tab1_summ) %>%
  select(-starts_with("SE")) %>%
  mutate(across(starts_with("perc"),
                ~ paste(round(., 3) * 100, "%"))) %>%
  add_column(space = " ",
             .before = 'perc_Wild') %>%
  kable(booktabs = T,
        digits = 0,
        format.args = list(big.mark = ','),
        linesep = "",
        align = "c",
        col.names = c(rep(" ", 6),
                      "Lower",
                      "Upper",
                      rep(" ", 2),
                      "Lower",
                      "Upper"),
        caption = "Steelhead abundance (adjusted for ladder re-ascension) at Priest Rapids Dam and the estimated number of overshoot fallback steelhead using the patch occupancy model, 2010-2017.") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c("Run Year" = 1,
                     "Wild" = 1, 
                     "Hatchery" = 1,
                     " " = 1,
                     "%" = 1, 
                     "Estimate" = 1,
                     "95% CI" = 2,
                     "%" = 1, 
                     "Estimate" = 1,
                     "95% CI" = 2)) %>%
  add_header_above(c(" " = 1,
                     "Adjusted Priest Rapids Dam Count" = 2,
                     " " = 1,
                     "Wild" = 4,
                     "Hatchery" = 4)) %>%
  add_header_above(c(" " = 4,
                     "Estimated Overshoot Fallback Abundance" = 8)) %>%
  row_spec(row = 8,
           hline_after = T)
```

Recreate Table 2 of manuscript:
```{r tab2}
top_nms <- avg_det %>%
  select(node,
         mean,
         mean_se) %>%
  mutate(river = recode(node,
                        "ICH" = "Snake",
                        "JD1" = "John Day",
                        "PRO" = "Yakima",
                        "PRV" = "Walla Walla",
                        "TMF" = "Umatilla")) %>%
  mutate(prnt_val = paste0(river, "\n",
                           node, "\n",
                           "(",
                           round(mean, 2), 
                           ", ",
                           round(mean_se, 2),
                           ")")) %>%
  select(node, prnt_val) %>%
  mutate(across(node,
                factor,
                levels = c("PRO", 
                           "ICH", 
                           "PRV",
                           "TMF",
                           "JD1"))) %>%
  arrange(node) %>%
  mutate(rep = 2) %>%
  select(-node) %>%
  add_row(prnt_val = " ",
          rep = 1,
          .before = 0)

flbk_abund %>%
  mutate(across(Year,
                ~ . - 1)) %>%
  mutate(across(Year,
                as.character)) %>%
  mutate(across(-Year,
                janitor::round_half_up)) %>%
  mutate(across(-Year,
                ~ as.character(prettyNum(., big.mark = ",")))) %>%
  bind_rows(flbk_abund %>%
              summarise(across(-Year,
                               mean)) %>%
              mutate(across(everything(),
                janitor::round_half_up)) %>%
              mutate(across(everything(),
                            ~ as.character(prettyNum(., big.mark = ",")))) %>%
              mutate(Year = "Mean") %>%
              bind_rows(flbk_abund %>%
                          summarise_at(vars(-Year),
                                       list(mean)) %>%
                          mutate(avg_tot = rowSums(.)) %>%
                          mutate(across(-avg_tot,
                                        ~ round(. / avg_tot, 3) * 100)) %>%
                          select(-avg_tot) %>%
                          mutate(across(everything(),
                                        as.character)) %>%
                          mutate(Year = "%"))) %>%
  kable(booktabs = T,
        align = "c",
        linesep = "",
        col.names = c("Run Year",
                      rep(c("W", "H"),
                          5)),
        caption = "Estimates of overshoot fallback steelhead downstream of Priest Rapids Dam, by sub-basin and PTAGIS location code. (PRO = Prosser Dam; ICH = Ice Harbor Dam; PRV = Pierce RV Park instream array; TMF = Three Mile Falls Dam; JD1 = Lower John Day instream array at McDonald Ferry). Parentheses indicate PIT tag detection probability (mean, mean of SE). W = wild and H = hatchery.") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(top_nms)
  
```


Recreate Table 3 of manuscript:
```{r tab3}
tab3 = obs_ovrsht_org %>%
  filter(location == "at_PRA") %>%
  select(Year, Origin, ovrst_tags = juv_tags) %>%
  filter(Origin == "Wild") %>%
  bind_cols(param_summ %>%
              filter(grepl("pred_ovrshts", param)) %>%
              slice(9:16) %>%
              # select(ovrst_PRD = mean,
              select(ovrst_PRD = `50%`,
                     prd_ci_low = `2.5%`,
                     prd_ci_upp = `97.5%`)) %>%
  bind_cols(param_summ %>%
              filter(grepl("phi", param)) %>%
              slice(9:16) %>%
              # select(phi = mean,
              select(phi = `50%`,
                     phi_ci_low = `2.5%`,
                     phi_ci_upp = `97.5%`)) %>%
  select(-Origin)

tab3 %>%
  mutate(Year = Year - 1) %>%
  mutate_at(vars(Year),
            list(as.character)) %>%
  bind_rows(tab3 %>%
              summarize(across(-Year,
                               mean)) %>%
                add_column(Year = "Mean",
                           .before = 0) %>%
                bind_rows(tab3 %>% 
                            summarize(across(-Year,
                                             sd)) %>%
                            add_column(Year = "SD",
                                       .before = 0))) %>%
  kable(booktabs = T,
        digits = c(rep(0, 5), rep(3, 3)),
        format.args = list(big.mark = ','),
        linesep = "",
        col.names = c("Run Year",
                      "Known Overshoot Fish",
                      "Estimate",
                      "Lower",
                      "Upper",
                      "Estimate",
                      "Lower",
                      "Upper"),
        caption = "Estimated abundance of overshoot steelhead at Priest Rapids Dam and the percentage of overshoot fallback or percentage of fish observed downstream of Priest Rapids Dam prior to spawning.") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" " = 3,
                     "95% CI" = 2,
                     " " = 1,
                     "95% CI" = 2)) %>%
  add_header_above(c(" " = 2,
                     "Estimated Wild Steelhead Overshoot Abundance" = 3,
                     "Overshoot Fallback Percentage\n(# fallbacks / # overshoots)" = 3))
  
```

Comparing another way to calculate $\phi$: fallback estimates from \@ref(tab:tab1) divided by total overshoots at Priest estimates from \@ref(tab:tab3):

```{r}
param_summ |>
  filter(str_detect(param,
                    "est_dwnstrm") |
           str_detect(param,
                      "pred_ovrshts") |
           str_detect(param,
                      "phi")) |>
  mutate(param_fam = str_split(param, "\\[", simplify = T)[,1],
         param_num = str_extract(param, "[:digit:]+"),
         param_num = as.numeric(param_num)) |>
  filter(param_num %in% c(9:16)) |>
  select(param_fam, param_num, 
         # est = mean) %>%
         est = `50%`) %>%
  pivot_wider(names_from = param_fam,
              values_from = est) %>%
  mutate(phi_v2 = est_dwnstrm / pred_ovrshts) |>
  mutate(Year = 2010:2017) |>
  select(Year,
         est_dwnstrm,
         pred_ovrshts,
         phi, phi_v2) %>%
  kable(booktabs = T,
        digits = c(rep(0, 3), rep(3, 2)),
        format.args = list(big.mark = ','),
        linesep = "",
        col.names = c("Run Year",
                      "Estimated Fallbacks",
                      "Estimated Overshoots",
                      "Estimated Phi",
                      "Version 2 Phi"),
        caption = "Estimated abundance of fallback steelhead downstream of Priest Rapids Dam, overshoot steelhead at Priest Rapids Dam and two ways of calculating probability of fallback success.") %>%
  kable_styling()


```

